{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from datasets import load_dataset\nimport random\nfrom transformers import RobertaTokenizer, T5ForConditionalGeneration, Trainer, TrainingArguments\nimport torch\nimport nltk","metadata":{"execution":{"iopub.status.busy":"2024-08-21T03:52:29.031930Z","iopub.execute_input":"2024-08-21T03:52:29.032331Z","iopub.status.idle":"2024-08-21T03:52:50.454748Z","shell.execute_reply.started":"2024-08-21T03:52:29.032301Z","shell.execute_reply":"2024-08-21T03:52:50.453891Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-08-21 03:52:38.768936: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-08-21 03:52:38.769059: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-08-21 03:52:38.924334: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the CodeSearchNet dataset for each language\ndataset_java = load_dataset('code_search_net', 'java')['train']\ndataset_python = load_dataset('code_search_net', 'python')['train']\ndataset_go = load_dataset('code_search_net', 'go')['train']","metadata":{"execution":{"iopub.status.busy":"2024-08-21T03:52:50.456776Z","iopub.execute_input":"2024-08-21T03:52:50.457554Z","iopub.status.idle":"2024-08-21T04:10:35.064699Z","shell.execute_reply.started":"2024-08-21T03:52:50.457519Z","shell.execute_reply":"2024-08-21T04:10:35.063879Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/8.44k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df3d0b2d6ec94cdd98eff68cdb68bf18"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/12.9k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39e6a96a49d54495ac01e0cd6d2807af"}},"metadata":{}},{"output_type":"stream","name":"stdin","text":"The repository for code_search_net contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/code_search_net.\nYou can avoid this prompt in future by passing the argument `trust_remote_code=True`.\n\nDo you wish to run the custom code? [y/N]  y\n"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/1.06G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e20081c7d1d24172891042cf4173a1fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/454451 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"89574b31e86248dfbe03a3a03e4c660c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/26909 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"212042dd0202479b9216bffc0bbbe3ee"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/15328 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfa96511a39e47e6bfad6296ee41b8b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/941M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff2e92311c364fb8b8fd95056c2879a5"}},"metadata":{}},{"text":"IOPub message rate exceeded.\nThe notebook server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--NotebookApp.iopub_msg_rate_limit`.\n\nCurrent values:\nNotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\nNotebookApp.rate_limit_window=3.0 (secs)\n\n","name":"stderr","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/14291 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db2e9c3a4f664c5d8bc43b49531abac9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/14242 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"515de69bcb9f494e969760683fd3895b"}},"metadata":{}}]},{"cell_type":"code","source":"# Function to sample 100 examples\ndef sample_data(dataset, num_samples=1000):\n    sampled_indices = random.sample(range(len(dataset)), num_samples)\n    return dataset.select(sampled_indices)\n\n# Sample 100 pairs from each language\nsampled_java = sample_data(dataset_java)\nsampled_python = sample_data(dataset_python)\nsampled_go = sample_data(dataset_go)\n\n# Function to split data into train, validation, and test sets\ndef train_val_test_split_data(dataset, val_size=0.1, test_size=0.1):\n    train_size = 1 - (val_size + test_size)\n    # Shuffle and split the dataset into train and temporary datasets\n    train_dataset = dataset.shuffle(seed=42).select(range(int(train_size * len(dataset))))\n    temp_dataset = dataset.shuffle(seed=42).select(range(int(train_size * len(dataset)), len(dataset)))\n    # Split the temporary dataset into validation and test datasets\n    split = int(len(temp_dataset) * (test_size / (test_size + val_size)))\n    val_dataset = temp_dataset.select(range(len(temp_dataset) - split))\n    test_dataset = temp_dataset.select(range(len(temp_dataset) - split, len(temp_dataset)))\n    return train_dataset, val_dataset, test_dataset\n\n# Split the data into train, validation, and test sets for each language\ntrain_java, val_java, test_java = train_val_test_split_data(sampled_java)\ntrain_python, val_python, test_python = train_val_test_split_data(sampled_python)\ntrain_go, val_go, test_go = train_val_test_split_data(sampled_go)\n\n# Load the tokenizer for CodeT5+\ntokenizer = RobertaTokenizer.from_pretrained('Salesforce/codet5p-220m')\n\n# Function to preprocess the datasets\ndef preprocess_function(examples):\n    # Use 'func_code_string' for the code and 'func_documentation_string' for the documentation\n    inputs = examples['func_code_string']\n    targets = examples['func_documentation_string']\n    # Tokenize the inputs and targets\n    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\")\n    # Tokenize the targets (docstrings) and add them as labels\n    labels = tokenizer(targets, max_length=128, truncation=True, padding=\"max_length\").input_ids\n    # Assign the labels to the model inputs\n    model_inputs[\"labels\"] = labels\n    return model_inputs\n\n# Preprocess the datasets\ntrain_java = train_java.map(preprocess_function, batched=True)\nval_java = val_java.map(preprocess_function, batched=True)\ntest_java = test_java.map(preprocess_function, batched=True)\n\ntrain_python = train_python.map(preprocess_function, batched=True)\nval_python = val_python.map(preprocess_function, batched=True)\ntest_python = test_python.map(preprocess_function, batched=True)\n\ntrain_go = train_go.map(preprocess_function, batched=True)\nval_go = val_go.map(preprocess_function, batched=True)\ntest_go = test_go.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-21T04:10:35.066088Z","iopub.execute_input":"2024-08-21T04:10:35.066415Z","iopub.status.idle":"2024-08-21T04:11:04.333146Z","shell.execute_reply.started":"2024-08-21T04:10:35.066386Z","shell.execute_reply":"2024-08-21T04:11:04.332081Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/1.48k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d70ecc039fe0420c99781b40c92a11e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/703k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cce2a377d12e460ebf8cc123b0eab414"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/294k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"348ab9897d3c45659a39d384c435e9e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"added_tokens.json:   0%|          | 0.00/2.00 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cbc46ce8a770471099aef141b0b88188"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/12.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6613aff5d7fc480fa499d2019c887887"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/800 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a98178277d1c4ea3a5ac8a33007420b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6df1261ae7a418684905dd705d1958a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b72a66656ad4accb1ebfc0ea894be84"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/800 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ffacc9826b7b4be3bb4e53e57ea43c74"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f117154d50224601bb0ed2ffee50a2eb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9e899068006414fa2d49898462f1414"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/800 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"186ee9fae7ed43f486777355f8844487"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a46a15bd18674a5e808389b6ccdfd12d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/100 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1b1184d7ef04938b2debb3b79bc7659"}},"metadata":{}}]},{"cell_type":"code","source":"# Import necessary libraries\nfrom transformers import T5ForConditionalGeneration, Trainer, TrainingArguments\nimport nltk\nimport torch\nfrom nltk.translate.bleu_score import SmoothingFunction\n\n# Load the pre-trained CodeT5+ model\nmodel = T5ForConditionalGeneration.from_pretrained('Salesforce/codet5p-220m')\n\n# Download necessary resources for nltk BLEU\nnltk.download('punkt')\n\n# Function to fine-tune the model\ndef fine_tune(model, train_dataset, val_dataset, output_dir):\n    training_args = TrainingArguments(\n        output_dir=output_dir,\n        num_train_epochs=3,\n        per_device_train_batch_size=8,\n        per_device_eval_batch_size=8,\n        eval_strategy=\"epoch\",  # Updated to 'eval_strategy'\n        save_steps=1000,\n        save_total_limit=2,\n        logging_dir='./logs',\n    )\n    trainer = Trainer(\n        model=model,\n        args=training_args,\n        train_dataset=train_dataset,\n        eval_dataset=val_dataset,\n        tokenizer=tokenizer,\n    )\n    trainer.train()\n    return model\n\n# Function to evaluate the model using BLEU score with smoothing\ndef evaluate_model(model, test_dataset, device):\n    model.to(device)  # Ensure the model is on the correct device\n    test_results = []\n\n    for example in test_dataset:\n        # Tokenize the input and move it to the appropriate device\n        inputs = tokenizer(example['func_code_string'], return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n        # Generate predictions with explicit max_new_tokens\n        outputs = model.generate(**inputs, max_new_tokens=100)\n        prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n        # Reference remains on the CPU (as it's just a string comparison)\n        reference = example['func_documentation_string']\n        test_results.append({\"prediction\": prediction, \"reference\": reference})\n\n    # Extract predictions and references\n    predictions = [result[\"prediction\"] for result in test_results]\n    references = [nltk.word_tokenize(result[\"reference\"]) for result in test_results]\n    tokenized_predictions = [nltk.word_tokenize(pred) for pred in predictions]\n\n    # Compute BLEU scores with smoothing\n    smoothie = SmoothingFunction().method4\n    bleu = nltk.translate.bleu_score.corpus_bleu([[ref] for ref in references], tokenized_predictions, smoothing_function=smoothie)\n    return {\"bleu\": bleu}\n\n# Define the device (GPU or CPU)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Fine-tune and evaluate sequentially on each language\n\n# Step 1: Fine-tune on Java\nmodel = fine_tune(model, train_java, val_java, './results_java')\njava_results_after_java = evaluate_model(model, test_java, device)\npython_results_after_java = evaluate_model(model, test_python, device)\ngo_results_after_java = evaluate_model(model, test_go, device)\n\n# Step 2: Fine-tune on Python\nmodel = fine_tune(model, train_python, val_python, './results_python')\njava_results_after_python = evaluate_model(model, test_java, device)\npython_results_after_python = evaluate_model(model, test_python, device)\ngo_results_after_python = evaluate_model(model, test_go, device)\n\n# Step 3: Fine-tune on Go\nmodel = fine_tune(model, train_go, val_go, './results_go')\njava_results_after_go = evaluate_model(model, test_java, device)\npython_results_after_go = evaluate_model(model, test_python, device)\ngo_results_after_go = evaluate_model(model, test_go, device)\n\n# Display results\nprint(\"Results after training on Java:\")\nprint(\"Java Test Results:\", java_results_after_java)\nprint(\"Python Test Results:\", python_results_after_java)\nprint(\"Go Test Results:\", go_results_after_java)\n\nprint(\"\\nResults after training on Python:\")\nprint(\"Java Test Results:\", java_results_after_python)\nprint(\"Python Test Results:\", python_results_after_python)\nprint(\"Go Test Results:\", go_results_after_python)\n\nprint(\"\\nResults after training on Go:\")\nprint(\"Java Test Results:\", java_results_after_go)\nprint(\"Python Test Results:\", python_results_after_go)\nprint(\"Go Test Results:\", go_results_after_go)\n","metadata":{"execution":{"iopub.status.busy":"2024-08-21T04:12:22.622612Z","iopub.execute_input":"2024-08-21T04:12:22.623404Z","iopub.status.idle":"2024-08-21T04:32:52.020126Z","shell.execute_reply.started":"2024-08-21T04:12:22.623363Z","shell.execute_reply":"2024-08-21T04:32:52.019165Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/768 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"25b42e3e7afe4eed95a213581958c2b0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/446M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d2dd6043ee24d4d82bb210bc0eb0d89"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n","output_type":"stream"},{"name":"stdout","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.17.7 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.17.4"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20240821_041321-s0nhqydc</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/devesudev-abv-iiitm-gwalior/huggingface/runs/s0nhqydc' target=\"_blank\">./results_java</a></strong> to <a href='https://wandb.ai/devesudev-abv-iiitm-gwalior/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/devesudev-abv-iiitm-gwalior/huggingface' target=\"_blank\">https://wandb.ai/devesudev-abv-iiitm-gwalior/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/devesudev-abv-iiitm-gwalior/huggingface/runs/s0nhqydc' target=\"_blank\">https://wandb.ai/devesudev-abv-iiitm-gwalior/huggingface/runs/s0nhqydc</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [300/300 03:42, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>3.507134</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>2.986073</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>2.823178</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [300/300 03:42, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>1.097229</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.615844</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.483468</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [300/300 03:42, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>0.532767</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>0.438091</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>No log</td>\n      <td>0.430539</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"Results after training on Java:\nJava Test Results: {'bleu': 0.10915195799493187}\nPython Test Results: {'bleu': 0.272069463064233}\nGo Test Results: {'bleu': 0.026967006049624365}\n\nResults after training on Python:\nJava Test Results: {'bleu': 0.0009397340718526295}\nPython Test Results: {'bleu': 0.6164936346733784}\nGo Test Results: {'bleu': 0.006472781283670101}\n\nResults after training on Go:\nJava Test Results: {'bleu': 0.01397301280093913}\nPython Test Results: {'bleu': 0.5525798712081508}\nGo Test Results: {'bleu': 0.1832540470814492}\n","output_type":"stream"}]},{"cell_type":"code","source":"#1000 codes t5+ no ewc","metadata":{"execution":{"iopub.status.busy":"2024-08-21T04:32:52.021818Z","iopub.execute_input":"2024-08-21T04:32:52.022135Z","iopub.status.idle":"2024-08-21T04:32:52.026979Z","shell.execute_reply.started":"2024-08-21T04:32:52.022109Z","shell.execute_reply":"2024-08-21T04:32:52.025975Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}